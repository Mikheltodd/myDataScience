{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nominal Categories\n",
    "\n",
    "A nominal categorical variable is a categorical variable with no intrinsic ordering to the categories.\n",
    "\n",
    "It’s impossible to calculate a mean or median. It would also be impossible to describe spread with statistics like variance, standard deviation, a range, IQR, or percentiles, because these statistics all rely on being able to order the data in some way. However, it is still possible to calculate the mode, the most common value in the dataset.\n",
    "\n",
    "We can do this in Python using the .value_counts() function. The .value_counts() function calculates the count of each value in a column and returns the result as a series. By default, .value_counts() orders categories in descending order by frequency, thus the top row in the output will be the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annadale-Huguenot-Prince's Bay-Eltingville    950\n",
      "Great Kills                                   761\n",
      "East New York                                 702\n",
      "Bayside-Bayside Hills                         665\n",
      "Rossville-Woodrow                             633\n",
      "                                             ... \n",
      "63                                              1\n",
      "39                                              1\n",
      "75                                              1\n",
      "BX33                                            1\n",
      "40                                              1\n",
      "Name: neighborhood, Length: 442, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read NYC Trees Data\n",
    "nyc_trees = pd.read_csv(\"./nyc_tree_census.csv\")\n",
    "\n",
    "# Get tree counts by neighborhood\n",
    "tree_counts = nyc_trees.neighborhood.value_counts()\n",
    "\n",
    "# Get neighborhoods with most trees\n",
    "greenest_neighborhood = tree_counts.index[0]\n",
    "\n",
    "print(tree_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Categorical Variables\n",
    "\n",
    "In order to calculate numerical statistics for ordered categories, we need to first assign numerical values to the categories. \n",
    "\n",
    "In Python, the easiest way to do this is to convert the variable to type 'category' using pandas.Categorical(). When converting a column to type 'category', we can also pass a list with the column’s categories (and True to the ordered parameter) to indicate the desired ordering.\n",
    "\n",
    "Variables stored as type category have an attribute (cat.codes) that converts the categories to numbers. This allows us to perform numerical operations on this categorical field. This allows us to calculate the median category using numpy’s median() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good' 'Poor' 'Fair' nan]\n",
      "Good\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read NYC trees data\n",
    "# nyc_trees = pd.read_csv(\"./nyc_tree_census.csv\")\n",
    "\n",
    "tree_health_statuses  = nyc_trees.health.unique()\n",
    "print(tree_health_statuses)\n",
    "\n",
    "health_categories = ['Poor', 'Fair', 'Good']\n",
    "\n",
    "nyc_trees['health'] = pd.Categorical(nyc_trees['health'], health_categories, ordered=True)\n",
    "\n",
    "# convert the categories to numbers to perform numerical operations\n",
    "median_healt_status_index = np.median(nyc_trees['health'].cat.codes)\n",
    "median_health_status = health_categories[int(median_healt_status_index)]\n",
    "print(median_health_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use cat.codes to return numeric values and perform a wide range of operations on categorical data as well. However, before performing any operations, you should check to make sure they make sense in the context of the data.\n",
    "\n",
    "When we use .cat.codes to translate these categories into integers, those integers have equal spacing. While translating categories to numbers is often necessary to store and use the order of the categories (for calculating a statistic like the median, which only relies on ordering, not spacing), we should not use those numbers to calculate statistics — such as the mean — for which the distance between values matters.\n",
    "\n",
    "In practice, researchers sometimes (albeit, incorrectly) report means for ordinal categories. For example, a researcher might want to analyze survey responses to the question \"Rate your happiness on a scale from 1 to 5 where 1 means 'very unhappy' and 5 means 'very happy'\".\n",
    "\n",
    "If that researcher calculates 'mean happiness score', they are assuming that the difference in happiness between a rating of 1 and 2 is the same as the difference in happiness for a rating of 3 and 4. In practice, this assumption is likely not true and should be acknowledged if reporting a mean of an ordinal categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Medium-Large (10-18in)\n",
      "1               Large (18-24in)\n",
      "2               Medium (3-10in)\n",
      "3            Very large (>24in)\n",
      "4            Very large (>24in)\n",
      "                  ...          \n",
      "49995    Medium-Large (10-18in)\n",
      "49996           Large (18-24in)\n",
      "49997                       NaN\n",
      "49998    Medium-Large (10-18in)\n",
      "49999             Small (0-3in)\n",
      "Name: tree_diam_category, Length: 50000, dtype: category\n",
      "Categories (5, object): ['Small (0-3in)' < 'Medium (3-10in)' < 'Medium-Large (10-18in)' < 'Large (18-24in)' < 'Very large (>24in)']\n",
      "11.27048\n",
      "1.97282\n"
     ]
    }
   ],
   "source": [
    "nyc_trees = pd.read_csv(\"nyc_tree_census2.csv\")\n",
    "\n",
    "nyc_trees.tree_diam_category = pd.Categorical(nyc_trees.tree_diam_category, ['Small (0-3in)', 'Medium (3-10in)', 'Medium-Large (10-18in)', 'Large (18-24in)','Very large (>24in)'], ordered=True)\n",
    "\n",
    "print(nyc_trees.tree_diam_category)\n",
    "\n",
    "# Get Mean Diam of diameter variable, `trunk_diam`\n",
    "mean_diam = np.average(nyc_trees.trunk_diam)\n",
    "print(mean_diam)\n",
    "\n",
    "# Get Mean Category of `tree_diam_category`\n",
    "mean_diam_cat = np.average(nyc_trees.tree_diam_category.cat.codes)\n",
    "print(mean_diam_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Categories: Spread\n",
    "\n",
    "The mean is not interpretable for ordinal categorical variables because the mean relies on the assumption of equal spacing between categories. \n",
    "\n",
    "Many other statistics we might normally use for numerical data rely on the mean. Because of this, these statistics aren’t appropriate for ordinal data. Remember that the standard deviation and variance both depend on the mean, without a mean, we can’t have a reliable standard deviation or variance either!\n",
    "\n",
    "We can rely on other summary statistics, like the proportion of the data within a range, or percentiles/quantiles. For example, consider the education variable from earlier. To calculate a range containing 80% of the data, we can use np.percentile():\n",
    "\n",
    "tenth_perc_ind = np.percentile(df['education'].cat.codes, 10)\n",
    "\n",
    "tenth_perc_cat = correct_order[int(tenth_perc_ind)]\n",
    "\n",
    "print(tenth_perc_cat) # output: 11th\n",
    " \n",
    "nintieth_perc_ind = np.percentile(df['education'].cat.codes, 90)\n",
    "\n",
    "nintieth_perc_cat = correct_order[int(nintieth_perc_ind)]\n",
    "\n",
    "print(nintieth_perc_cat): #output: Bachelors\n",
    "\n",
    "This tells us that at least 80% of respondents range in \"education level\" from 11th grade to a Bachelor’s degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium (3-10in)\n",
      "Large (18-24in)\n"
     ]
    }
   ],
   "source": [
    "size_labels_ordered = ['Small (0-3in)', 'Medium (3-10in)', 'Medium-Large (10-18in)', 'Large (18-24in)','Very large (>24in)']\n",
    "\n",
    "nyc_trees.tree_diam_category = pd.Categorical(nyc_trees.tree_diam_category, size_labels_ordered, ordered=True)\n",
    "\n",
    "# Calculate 25th Percentile Category\n",
    "p25_perc_ind = np.percentile(nyc_trees.tree_diam_category.cat.codes, 25)\n",
    "p25_tree_diam_category = size_labels_ordered[int(p25_perc_ind)]\n",
    "print(p25_tree_diam_category)\n",
    "\n",
    "# Calculate 75th Percentile Category\n",
    "p75_perc_ind = np.percentile(nyc_trees.tree_diam_category.cat.codes, 75)\n",
    "p75_tree_diam_category = size_labels_ordered[int(p75_perc_ind)]\n",
    "print(p75_tree_diam_category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Proportions\n",
    "\n",
    "We can calculate proportions by dividing the frequency by the number of observations in the data.\n",
    "We can also calculate proportions using .value_counts() by setting the normalize parameter equal to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alive    0.9539\n",
      "Stump    0.0267\n",
      "Dead     0.0194\n",
      "Name: status, dtype: float64\n",
      "Alive    0.9539\n",
      "Stump    0.0267\n",
      "Dead     0.0194\n",
      "Name: status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tree_status_proportions_1 = nyc_trees.status.value_counts()/len(nyc_trees.status)\n",
    "tree_status_proportions_2 = nyc_trees.status.value_counts(normalize = True)\n",
    "print(tree_status_proportions_1)\n",
    "print(tree_status_proportions_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "You can set the dropna parameter in .value_counts() to determine how NaN values are handled in summaries of data.\n",
    "\n",
    "When we divide the frequency of each category by len(df['workclass']), we’re calculating the proportion of a specific workclass group as a portion of all people in the dataset. This is equivalent to setting dropna = False in the call to value_counts().\n",
    "\n",
    "In contrast, using .value_counts(normalize = True) (or .value_counts(normalize = True, dropna = True) to be explicit) returns proportion of a specific workclass group as a portion of people in the dataset who responded to this question.\n",
    "\n",
    "if we don’t include the missing values in our denominator, we observe slightly larger proportions in each category (and no NaN category) in the above output. It is important to think about how you want to deal with missing data when summarizing a categorical variable and then interpret resulting values appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good    0.810986\n",
      "Fair    0.146871\n",
      "Poor    0.042143\n",
      "Name: health, dtype: float64\n",
      "Good    0.7736\n",
      "Fair    0.1401\n",
      "NaN     0.0461\n",
      "Poor    0.0402\n",
      "Name: health, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "health_proportions = nyc_trees.health.value_counts(normalize = True)\n",
    "print(health_proportions)\n",
    "\n",
    "health_proportions_2 = nyc_trees.health.value_counts(normalize = True, dropna = False)\n",
    "print(health_proportions_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Categorical Variables\n",
    "\n",
    "In Python, the same behavior holds for columns coded as True/False because True gets coerced to 1 and False gets coerced to 0 (this is also true in most other programming languages used by data scientists). Similarly, we can calculate the proportion equal to 1 or True by taking the mean of the column. This works because the mean is just the sum of all values in the column (which is the frequency of 1s or Trues) divided by the number of values in the column\n",
    "\n",
    "Finally, we can make use of this nifty trick for any variable by using a conditional to translate a non-binary variable into True and False values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47695\n",
      "0.9539\n",
      "1788\n",
      "0.03576\n"
     ]
    }
   ],
   "source": [
    "living_frequency = np.sum(nyc_trees.status == 'Alive')\n",
    "living_proportion = np.average(nyc_trees.status == 'Alive')\n",
    "print(living_frequency)\n",
    "print(living_proportion)\n",
    "\n",
    "giant_frequency = np.sum(nyc_trees.trunk_diam > 30)\n",
    "giant_proportion = np.average(nyc_trees.trunk_diam > 30)\n",
    "print(giant_frequency)\n",
    "print(giant_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EventID                      EventType           StartDateTime  \\\n",
      "0   446168                Shooting Permit  10/19/2018 02:00:00 PM   \n",
      "1   186438                Shooting Permit  10/30/2014 07:00:00 AM   \n",
      "2   445255                Shooting Permit  10/20/2018 07:00:00 AM   \n",
      "3   128794  Theater Load in and Load Outs  11/16/2013 12:01:00 AM   \n",
      "4    43547                Shooting Permit  01/10/2012 07:00:00 AM   \n",
      "\n",
      "              EndDateTime    Borough           Category  SubCategoryName  \n",
      "0  10/20/2018 02:00:00 AM  Manhattan               Film          Feature  \n",
      "1  10/31/2014 02:00:00 AM     Queens         Television  Episodic series  \n",
      "2  10/20/2018 06:00:00 PM   Brooklyn  Still Photography   Not Applicable  \n",
      "3  11/17/2013 06:00:00 AM  Manhattan            Theater          Theater  \n",
      "4  01/10/2012 07:00:00 PM   Brooklyn         Television  Episodic series  \n",
      "Manhattan        149\n",
      "Brooklyn          89\n",
      "Queens            21\n",
      "Bronx             10\n",
      "Staten Island      2\n",
      "Name: Borough, dtype: int64\n",
      "Television           5271\n",
      "Film                 1765\n",
      "Theater               966\n",
      "Commercial            878\n",
      "Still Photography     658\n",
      "WEB                   313\n",
      "Student                72\n",
      "Documentary            48\n",
      "Music Video            28\n",
      "Name: Category, dtype: int64\n",
      "Episodic series            2916\n",
      "Feature                    1382\n",
      "Not Applicable             1381\n",
      "Cable-episodic             1033\n",
      "Theater                     966\n",
      "Commercial                  686\n",
      "Pilot                       271\n",
      "News                        202\n",
      "Cable-other                 126\n",
      "Reality                     124\n",
      "Morning Show                121\n",
      "Short                       120\n",
      "Promo                       112\n",
      "Made for TV/mini-series      90\n",
      "Variety                      76\n",
      "Student Film                 65\n",
      "Special/Awards Show          59\n",
      "Cable-daily                  55\n",
      "Industrial/Corporate         54\n",
      "Talk Show                    48\n",
      "PSA                          27\n",
      "Game show                    25\n",
      "Signed Artist                15\n",
      "Children                     12\n",
      "Syndication/First Run        11\n",
      "Independent Artist            9\n",
      "Magazine Show                 8\n",
      "Daytime soap                  5\n",
      "Name: SubCategoryName, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read CSV\n",
    "film_permits = pd.read_csv('film_permits.csv')\n",
    "\n",
    "# Look first few rows\n",
    "print(film_permits.head()) \n",
    "\n",
    "# Nominal Vars\n",
    "nominalvars = ['EventType', 'Borough', 'Category', 'SubCategoryName']\n",
    "\n",
    "# Ordinal Vars - We might consider an Id like 'EventID' an ordinal variable in some situations\n",
    "\n",
    "# Borough with the most permits for pilot episodes\n",
    "print(film_permits[film_permits.SubCategoryName == 'Pilot'].Borough.value_counts())\n",
    "\n",
    "# Summarize the Top Categories\n",
    "print(film_permits.Category.value_counts())\n",
    "\n",
    "# Summarize the Top Subcategories\n",
    "print(film_permits.SubCategoryName.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  buying_cost maintenance_cost doors capacity luggage safety acceptability  \\\n",
      "0       vhigh              low     4        4   small    med         unacc   \n",
      "1       vhigh              med     3        4   small   high           acc   \n",
      "2         med             high     3        2     med   high         unacc   \n",
      "3         low              med     4     more     big    low         unacc   \n",
      "4         low             high     2     more     med   high           acc   \n",
      "\n",
      "  manufacturer_country  \n",
      "0                China  \n",
      "1               France  \n",
      "2        United States  \n",
      "3        United States  \n",
      "4          South Korea  \n",
      "Index(['buying_cost', 'maintenance_cost', 'doors', 'capacity', 'luggage',\n",
      "       'safety', 'acceptability', 'manufacturer_country'],\n",
      "      dtype='object')\n",
      "Japan            228\n",
      "Germany          218\n",
      "South Korea      159\n",
      "United States    138\n",
      "Italy             97\n",
      "France            87\n",
      "China             73\n",
      "Name: manufacturer_country, dtype: int64\n",
      "Japan\n",
      "Japan            0.228\n",
      "Germany          0.218\n",
      "South Korea      0.159\n",
      "United States    0.138\n",
      "Italy            0.097\n",
      "France           0.087\n",
      "China            0.073\n",
      "Name: manufacturer_country, dtype: float64\n",
      "['vhigh' 'med' 'low' 'high']\n",
      "med\n",
      "small    0.339\n",
      "med      0.333\n",
      "big      0.328\n",
      "Name: luggage, dtype: float64\n",
      "small    0.339\n",
      "med      0.333\n",
      "big      0.328\n",
      "Name: luggage, dtype: float64\n",
      "2        239\n",
      "3        252\n",
      "4        263\n",
      "5more    246\n",
      "Name: doors, dtype: int64\n",
      "239\n",
      "246\n",
      "0.246\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "car_eval = pd.read_csv('car_eval_dataset.csv')\n",
    "print(car_eval.head())\n",
    "print(car_eval.columns)\n",
    "print(car_eval.manufacturer_country.value_counts())\n",
    "print(car_eval.manufacturer_country.value_counts().index[0])\n",
    "print(car_eval.manufacturer_country.value_counts(normalize = True))\n",
    "\n",
    "print(car_eval.buying_cost.unique())\n",
    "buying_cost_categories = ['low', 'med', 'high', 'vhigh']\n",
    "car_eval.buying_cost = pd.Categorical(car_eval.buying_cost, buying_cost_categories, ordered=True)\n",
    "median_index = np.median(car_eval.buying_cost.cat.codes)\n",
    "median_category = buying_cost_categories[int(median_index)]\n",
    "print(median_category)\n",
    "\n",
    "luggage_frequency = car_eval.luggage.value_counts(dropna=False)/len(car_eval.luggage)\n",
    "luggage_proportions = car_eval.luggage.value_counts(normalize=True)\n",
    "print(luggage_frequency)\n",
    "print(luggage_proportions)\n",
    "\n",
    "print(car_eval.doors.value_counts().sort_index())\n",
    "freq_2 = (car_eval['doors']=='2').sum()\n",
    "print(freq_2)\n",
    "freq_5more = (car_eval['doors']=='5more').sum()\n",
    "prop_5more = (car_eval['doors']=='5more').mean()\n",
    "print(freq_5more)\n",
    "print(prop_5more)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
